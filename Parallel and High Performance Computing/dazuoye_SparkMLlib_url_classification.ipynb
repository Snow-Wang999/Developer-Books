{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "V7CekNzRFeYZ",
        "lj7DsGo4eSjl",
        "gYgSM_RXPUBX",
        "0_yvnB3wDCeN",
        "ejQIimhvfmiB",
        "y6FHvvzVTu56",
        "J2Y-s5yMpdlJ",
        "gNeQyUwpIJDR",
        "EH_CI7iVIRBo"
      ],
      "authorship_tag": "ABX9TyP/eZmgLUSG2w11V9H3YvFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snow-Wang999/Developer-Books/blob/master/Parallel%20and%20High%20Performance%20Computing/dazuoye_SparkMLlib_url_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7CekNzRFeYZ"
      },
      "source": [
        "## 1.1Install sparkNLP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahCB8nhSBLhS",
        "outputId": "4f4c1f99-d9d1-48b0-df58-8770b5a7230c"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-28 15:38:31--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-28 15:38:31--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.3 and Spark NLP 3.1.1\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-06-28 15:38:31 (1.77 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,777 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [909 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [505 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,652 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:20 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Ign:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [599 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,220 kB]\n",
            "Fetched 13.1 MB in 4s (3,401 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1MB 61kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 53.7MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK_UyY4fBQff",
        "outputId": "f336a6ef-991a-4405-ce45-e66f8c0e1457"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version: 3.1.1\n",
            "Apache Spark version: 3.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v_h9a7zI4tl"
      },
      "source": [
        "#!pip install elephas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj7DsGo4eSjl"
      },
      "source": [
        "##1.2 Operate environment configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqC79j5BeFH9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import lower, col, udf\n",
        "from pyspark.sql.functions import isnull, when, count, col\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import mean, min, max\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import RegexTokenizer\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.ml.feature import NGram\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.classification import NaiveBayes, LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0M-ex2zBXyJ"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU-Kl77NF4-s",
        "outputId": "1d35dff1-2d7d-401f-9d0d-fceefc70850c"
      },
      "source": [
        "'''\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from elephas.spark_model import SparkModel\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D\\nfrom tensorflow.keras.optimizers import SGD\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nfrom elephas.spark_model import SparkModel\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_C4icXyPipO"
      },
      "source": [
        "#from pyspark.ml.linalg import Vectors\n",
        "#from pyspark.ml.linalg import SparseVector, DenseVector\n",
        "#from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "#from pyspark.mllib.regression import LabeledPoint\n",
        "#from pyspark.mllib.classification import LogisticRegressionWithSGD, SVMWithSGD, SVMModel, NaiveBayes, NaiveBayesModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvhbDvRetf5O"
      },
      "source": [
        "#from six.moves import zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTXC8Q8UYE1"
      },
      "source": [
        "## 1.3 upload files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWy_6Ri3gS2M",
        "outputId": "fcb1ef1d-658a-4950-bfe1-d103f3d3c688"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSJ-pUlTAQhz",
        "outputId": "9592c120-0ae9-4444-d1b7-8c7edc443ded"
      },
      "source": [
        "df_2 = spark.read.csv('/content/drive/MyDrive/archive/dmoz.csv',inferSchema=True, header=True,)\n",
        "df_2 = df_2.withColumnRenamed(\"desc\",\"text\")\n",
        "df_2 = df_2.withColumn('text', lower(col('text')))\\\n",
        "      .withColumn('title', lower(col('title')))\n",
        "df_2.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+----------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|_c0|category|title                                                     |text                                                                                                                                                                                                                         |\n",
            "+---+--------+----------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1  |Arts    |about.com: animation guide                                |keep up with developments in online animation for all skill levels. download tools, and seek inspiration from online work.                                                                                                   |\n",
            "|2  |Arts    |toonhound                                                 |british cartoon, animation and comic strip creations - links, reviews and news from the uk.                                                                                                                                  |\n",
            "|3  |Arts    |enculturation: from mouse to mouse: overcoming information|essay by patricia pisters on the animated image and its changing relationship with the cinematic image.                                                                                                                      |\n",
            "|4  |Arts    |digital media fx: the history of animation                |michael crandol takes an exhaustive look at the history of animation and animators/visionaries like max fleisher, walter lantz, and otto messmer.                                                                            |\n",
            "|5  |Arts    |spark online: only genius is genius                       |chris romano feels that the proliferation of flash and other web-based animation technologies has not improved the overall quality of animation and cartoons.                                                                |\n",
            "|6  |Arts    |richard's animated divots                                 |chronology of animated movies, television programs, and short cartoons. includes animation filmographies and a list of anime television series.                                                                              |\n",
            "|7  |Arts    |nini's bishonen dungeon                                   |shrines to vega, taiki, dilandau, and tiger eye, as well as fan art, adoptions, and links.                                                                                                                                   |\n",
            "|8  |Arts    |site for liz's anime favorites                            |shrines to duo, ryoko, shampoo, katy the kitty, lady une, mimete, junjun, parapara, and sailor saturn with images, profiles, and links.                                                                                      |\n",
            "|9  |Arts    |azure valley                                              |dedicated to anthropomorphic characters. fan art, images, profiles, and links.                                                                                                                                               |\n",
            "|10 |Arts    |neko central                                              |image galleries, descriptions, information, and media on cats from different series.                                                                                                                                         |\n",
            "|11 |Arts    |chibi hime's magic shoppe 2                               |shrines to escaflowne's dilandau, final fantasy's vincent, soultaker's kyousuke, and hsi wu from jackie chan adventures. includes images, information, and fan fiction.                                                      |\n",
            "|12 |Arts    |animen                                                    |features men from fushigi yuugi, sailor moon, escaflowne, rayearth, gundam wing, bubblegum crisis/ad police, tenchi muyo, utena, and ayashi no ceres. profiles, commentary, polls, fan fiction, images, downloads, and links.|\n",
            "|13 |Arts    |american high school anime association                    |mission statement, reviews, member area, links, and how to join.                                                                                                                                                             |\n",
            "|14 |Arts    |anime alberta                                             |message board, features, information, events and several groups. alberta, canada.                                                                                                                                            |\n",
            "|15 |Arts    |yale anime society                                        |society charter, image and midi archive, schedule, member list, and links. yale university, connecticut, usa.                                                                                                                |\n",
            "|16 |Arts    |no-name anime society                                     |information about monthly showings and copies of newsletters. saratoga, california, usa.                                                                                                                                     |\n",
            "|17 |Arts    |carolina otaku uprising                                   |general information, showing schedule, kendo club, and links. chapel hill, north carolina, usa.                                                                                                                              |\n",
            "|18 |Arts    |mit anime club                                            |viewing schedule, club information, art, library, and links. cambridge, massachusetts, usa at massachusetts institute of technology.                                                                                         |\n",
            "|19 |Arts    |university of richmond japanese anime club                |ur anime is no longer an active organization. however, the history of the club and all anime convention photo galleries are still showcased as a service to the public. virginia, usa at university of richmond.             |\n",
            "|20 |Arts    |animated perspectives                                     |history, constitution, showings, and tape library. stony brook, new york, usa.                                                                                                                                               |\n",
            "+---+--------+----------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_c_oAUWC3Y_",
        "outputId": "1ff6d3ef-5673-4c93-be5b-6f0f5ab05411"
      },
      "source": [
        "df_2.select([count(when(isnull(c), c)).alias(c) for c in df_2.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+-----+----+\n",
            "|_c0|category|title|text|\n",
            "+---+--------+-----+----+\n",
            "|  0|       0|    0|   0|\n",
            "+---+--------+-----+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTftS80IDQ-f",
        "outputId": "142dd625-b523-4e0e-c595-64692fb70bc9"
      },
      "source": [
        "df_2.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1195851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtCqZGenDH7D",
        "outputId": "86df690b-98cb-46fa-d1bb-85a6a901e2a4"
      },
      "source": [
        "df_2.groupby(\"Category\").count()\\\n",
        "    .orderBy(\"count\",ascending=False)\\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------+\n",
            "|  Category| count|\n",
            "+----------+------+\n",
            "|  Business|204910|\n",
            "|   Society|195880|\n",
            "|      Arts|193914|\n",
            "|   Science| 96766|\n",
            "| Computers| 93204|\n",
            "|    Sports| 85376|\n",
            "|Recreation| 83618|\n",
            "|  Shopping| 78184|\n",
            "|    Health| 50388|\n",
            "| Reference| 47428|\n",
            "|     Games| 36454|\n",
            "|      Home| 22241|\n",
            "|      News|  7488|\n",
            "+----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW-m98XqD6I3",
        "outputId": "e9412b17-1fcc-488d-823f-896767f566e5"
      },
      "source": [
        "df = df_2.select(\"Category\",\"title\",\"text\")\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+\n",
            "|Category|               title|                text|\n",
            "+--------+--------------------+--------------------+\n",
            "|    Arts|about.com: animat...|keep up with deve...|\n",
            "|    Arts|           toonhound|british cartoon, ...|\n",
            "|    Arts|enculturation: fr...|essay by patricia...|\n",
            "|    Arts|digital media fx:...|michael crandol t...|\n",
            "|    Arts|spark online: onl...|chris romano feel...|\n",
            "+--------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbM6M_-LDUoh",
        "outputId": "fcabed7d-be92-4833-817c-c089c8135d06"
      },
      "source": [
        "selected_rows = df.groupby(\"Category\")\\\n",
        "    .count()\\\n",
        "    .orderBy(\"count\",ascending=False)\\\n",
        "    .limit(5)\\\n",
        "    .collect()\n",
        "selected_topics = [row.Category for row in selected_rows]\n",
        "selected_topics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Business', 'Society', 'Arts', 'Science', 'Computers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_9Xa_yiDGCm",
        "outputId": "87e21b1a-814a-4673-9812-aef5462c3bcd"
      },
      "source": [
        "df = df.filter(F.col(\"Category\").isin(selected_topics))\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwyG51WwEjWc",
        "outputId": "2e65fa9b-b8d3-4213-bcb2-b79809952679"
      },
      "source": [
        "df.groupby(\"Category\").count()\\\n",
        "    .orderBy(\"count\",ascending=False)\\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+\n",
            "| Category| count|\n",
            "+---------+------+\n",
            "| Business|204910|\n",
            "|  Society|195880|\n",
            "|     Arts|193914|\n",
            "|  Science| 96766|\n",
            "|Computers| 93204|\n",
            "+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UImECvWO51ro",
        "outputId": "d9b946b5-0e83-4f2e-e8fc-8de3b1b52db6"
      },
      "source": [
        "df_c1 = df.filter(F.col('Category')=='Business').limit(10000)\n",
        "df_c2 = df.filter(F.col('Category')=='Society').limit(10000)\n",
        "df_c3 = df.filter(F.col('Category')=='Arts').limit(10000)\n",
        "df_c4 = df.filter(F.col('Category')=='Science').limit(10000)\n",
        "df_c5 = df.filter(F.col('Category')=='Computers').limit(10000)\n",
        "df = df_c1.union(df_c2)\\\n",
        "      .union(df_c3)\\\n",
        "      .union(df_c4)\\\n",
        "      .union(df_c5)\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjqTIzCV6q2x",
        "outputId": "45bfbe53-3e38-467c-89ce-4916ce6afe66"
      },
      "source": [
        "df.groupby(\"Category\").count()\\\n",
        "    .orderBy(\"count\",ascending=False)\\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "| Category|count|\n",
            "+---------+-----+\n",
            "|Computers|10000|\n",
            "|  Science|10000|\n",
            "|  Society|10000|\n",
            "|     Arts|10000|\n",
            "| Business|10000|\n",
            "+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiQ2LeuZqjM1"
      },
      "source": [
        "# 3.split data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-r4iaKVfok0"
      },
      "source": [
        "## 3.1 random split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYNXende4heh",
        "outputId": "69c591eb-0fcb-42c5-b8ac-ad79042df5b4"
      },
      "source": [
        "df_train, df_test, df_validation = df.randomSplit([0.7, 0.15, 0.15], seed=2021)\n",
        "print(df_train.count())\n",
        "print(df_test.count())\n",
        "print(df_validation.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34868\n",
            "7568\n",
            "7564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO0uF2AvSuot"
      },
      "source": [
        "## 1.4 split text,title and category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdyKTvZNSs6i"
      },
      "source": [
        "df_train_x = df_train.select(\"title\",\"text\")\n",
        "df_train_y = df_train.select(\"Category\")\n",
        "df_test_x = df_test.select(\"title\",\"text\")\n",
        "df_test_y = df_test.select(\"Category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbmcMRjgqcmd"
      },
      "source": [
        "# 2. preprocessing(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xtK_gq1UUvc"
      },
      "source": [
        "## 2.1 pipeline ml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgb4_EeSR2rI"
      },
      "source": [
        "#regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "#stopwordList = [\"http\",\"www\",\"com\",\"html\",\"htm\"]\n",
        "#remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords=stopwordList)\n",
        "#word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol='words', outputCol='features')\n",
        "#ngram = NGram(n=1, inputCol=\"filtered\", outputCol=\"ngrams\")\n",
        "#cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=20, minDF=1.0)\n",
        "#hashingTF = HashingTF(inputCol=\"ngrams\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "#cv = CountVectorizer(inputCol=\"ngrams\", outputCol=\"rawFeatures\", vocabSize=20, minDF=1.0)\n",
        "#idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "#pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
        "#indexer = StringIndexer(inputCol=\"Category\", outputCol=\"label\")\n",
        "#lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "#nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", smoothing=111, modelType=\"multinomial\")\n",
        "#pipeline = Pipeline(stages=[regexTokenizer,  word2Vec, indexer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4VqCJWePav"
      },
      "source": [
        "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "ngram_1 = NGram(n=1, inputCol=\"filtered\", outputCol=\"ngram_1\")\n",
        "ngram_2 = NGram(n=2, inputCol=\"filtered\", outputCol=\"ngram_2\")\n",
        "hashingTF_1 = HashingTF(inputCol=\"ngram_1\", outputCol=\"rawFeatures_1\", numFeatures=150)\n",
        "hashingTF_2 = HashingTF(inputCol=\"ngram_2\", outputCol=\"rawFeatures_2\", numFeatures=150)\n",
        "cv_1 = CountVectorizer(inputCol=\"ngram_1\", outputCol=\"rawFeatures_3\", vocabSize=150, minDF=2.0)\n",
        "cv_2 = CountVectorizer(inputCol=\"ngram_2\", outputCol=\"rawFeatures_4\", vocabSize=150, minDF=2.0)\n",
        "idf_hash_1 = IDF(inputCol=\"rawFeatures_1\", outputCol=\"features_1\")\n",
        "idf_hash_2 = IDF(inputCol=\"rawFeatures_2\", outputCol=\"features_2\")\n",
        "idf_cv_1 = IDF(inputCol=\"rawFeatures_3\", outputCol=\"features_3\")\n",
        "idf_cv_2 = IDF(inputCol=\"rawFeatures_4\", outputCol=\"features_4\")\n",
        "pca_1 = PCA(k=3, inputCol=\"features_1\", outputCol=\"pcaFeatures_1\")\n",
        "pca_2 = PCA(k=3, inputCol=\"features_2\", outputCol=\"pcaFeatures_2\")\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"Category\", outputCol=\"label\")\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", smoothing=1, modelType=\"multinomial\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees = 100, maxDepth = 4, maxBins = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I2RBo_Vgdxu"
      },
      "source": [
        "asseminputCols = [\"features_1\",\"features_2\"]\n",
        "assembler = VectorAssembler(inputCols=asseminputCols, outputCol=\"features\")\n",
        "pipeline = Pipeline(stages=[regexTokenizer, remover, ngram_1, ngram_2, hashingTF_1, hashingTF_2, idf_hash_1, idf_hash_2, assembler, indexer, nb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqaw2NBJosEa"
      },
      "source": [
        "pipeline_2 = Pipeline(stages=[regexTokenizer, remover, ngram_1, ngram_2, hashingTF_1, hashingTF_2, idf_hash_1, idf_hash_2, assembler, indexer, lr])\n",
        "pipeline_3 = Pipeline(stages=[regexTokenizer, remover, ngram_1, ngram_2, hashingTF_1, hashingTF_2, idf_hash_1, idf_hash_2, assembler, indexer, rf])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNeQyUwpIJDR"
      },
      "source": [
        "## 2.2 pipeline sparknlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjTnvXYnPzI0"
      },
      "source": [
        "preprocess text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgrrihAp-jSf"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igFfqXsECdiI"
      },
      "source": [
        "sentence_detector = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZvflLBRGZnX"
      },
      "source": [
        "regexTokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpQdsIEiC7rn",
        "outputId": "c9829970-b817-49d7-983c-06321eb3a21c"
      },
      "source": [
        "stop_words_cleaner = StopWordsCleaner\\\n",
        "    .pretrained('stopwords_en', 'en')\\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords_en download started this may take some time.\n",
            "Approximate size to download 2.9 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2mEzcwdCkiz",
        "outputId": "20793f27-6bf2-41cb-f739-ae63635757d6"
      },
      "source": [
        "lemmatizer = LemmatizerModel\\\n",
        "    .pretrained(\"lemma_antbnc\", \"en\") \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMe8IUXDAWF"
      },
      "source": [
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"lemma\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWULzfnSHxS5"
      },
      "source": [
        "ngram_1 = NGram(n=1, inputCol=\"token_features\", outputCol=\"ngram_1\")\n",
        "ngram_2 = NGram(n=2, inputCol=\"token_features\", outputCol=\"ngram_2\")\n",
        "hashingTF_1 = HashingTF(inputCol=\"ngram_1\", outputCol=\"rawFeatures_1\", numFeatures=150)\n",
        "hashingTF_2 = HashingTF(inputCol=\"ngram_2\", outputCol=\"rawFeatures_2\", numFeatures=150)\n",
        "idf_hash_1 = IDF(inputCol=\"rawFeatures_1\", outputCol=\"features_1\")\n",
        "idf_hash_2 = IDF(inputCol=\"rawFeatures_2\", outputCol=\"features_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P-LG6kfPp_8"
      },
      "source": [
        "preprocess title data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD6qW7q-2kDX"
      },
      "source": [
        "document_assembler_2 = DocumentAssembler()\\\n",
        "    .setInputCol(\"title\")\\\n",
        "    .setOutputCol(\"document_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIHZkt0H2tCo"
      },
      "source": [
        "regexTokenizer_2 = Tokenizer() \\\n",
        "    .setInputCols([\"document_2\"]) \\\n",
        "    .setOutputCol(\"token_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKJ9xi4221_Q"
      },
      "source": [
        "finisher_2 = Finisher() \\\n",
        "    .setInputCols([\"token_2\"]) \\\n",
        "    .setOutputCols([\"token_features_2\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgwYBx-b027T"
      },
      "source": [
        "ngram_3 = NGram(n=1, inputCol=\"token_features_2\", outputCol=\"ngram_3\")\n",
        "ngram_4 = NGram(n=2, inputCol=\"token_features_2\", outputCol=\"ngram_4\")\n",
        "hashingTF_3 = HashingTF(inputCol=\"ngram_3\", outputCol=\"rawFeatures_3\", numFeatures=150)\n",
        "hashingTF_4 = HashingTF(inputCol=\"ngram_4\", outputCol=\"rawFeatures_4\", numFeatures=150)\n",
        "idf_hash_3 = IDF(inputCol=\"rawFeatures_3\", outputCol=\"features_3\")\n",
        "idf_hash_4 = IDF(inputCol=\"rawFeatures_4\", outputCol=\"features_4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0qV03yH8m1"
      },
      "source": [
        "asseminputCols = [\"features_1\",'features_2',\"features_3\",'features_4']\n",
        "assembler = VectorAssembler(inputCols=asseminputCols, outputCol=\"features\")\n",
        "indexer = StringIndexer(inputCol=\"Category\", outputCol=\"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXKrIlY8H4ID"
      },
      "source": [
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", smoothing=0.001, modelType=\"multinomial\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees = 100, maxDepth = 4, maxBins = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJVRsFlNSGQx"
      },
      "source": [
        "pipeline_nb = Pipeline(\n",
        "            stages=[\n",
        "                document_assembler,\n",
        "                sentence_detector, \n",
        "                regexTokenizer,\n",
        "                stop_words_cleaner,\n",
        "                lemmatizer,\n",
        "                finisher, \n",
        "                ngram_1, \n",
        "                ngram_2, \n",
        "                hashingTF_1, \n",
        "                hashingTF_2, \n",
        "                idf_hash_1, \n",
        "                idf_hash_2, \n",
        "                document_assembler_2,\n",
        "                regexTokenizer_2,\n",
        "                finisher_2,\n",
        "                ngram_3, \n",
        "                ngram_4, \n",
        "                hashingTF_3, \n",
        "                hashingTF_4, \n",
        "                idf_hash_3, \n",
        "                idf_hash_4,\n",
        "                assembler, \n",
        "                indexer,\n",
        "                nb\n",
        "                  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx7e3Na9OHE2"
      },
      "source": [
        "pipeline_lr = Pipeline(\n",
        "            stages=[\n",
        "                document_assembler,\n",
        "                sentence_detector, \n",
        "                regexTokenizer,\n",
        "                stop_words_cleaner,\n",
        "                lemmatizer,\n",
        "                finisher, \n",
        "                ngram_1, \n",
        "                ngram_2, \n",
        "                hashingTF_1, \n",
        "                hashingTF_2, \n",
        "                idf_hash_1, \n",
        "                idf_hash_2, \n",
        "                document_assembler_2,\n",
        "                regexTokenizer_2,\n",
        "                finisher_2,\n",
        "                ngram_3, \n",
        "                ngram_4, \n",
        "                hashingTF_3, \n",
        "                hashingTF_4, \n",
        "                idf_hash_3, \n",
        "                idf_hash_4,\n",
        "                assembler, \n",
        "                indexer,\n",
        "                lr\n",
        "                  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnQ7U4fXOKvv"
      },
      "source": [
        "pipeline_rf = Pipeline(\n",
        "            stages=[\n",
        "                document_assembler,\n",
        "                sentence_detector, \n",
        "                regexTokenizer,\n",
        "                stop_words_cleaner,\n",
        "                lemmatizer,\n",
        "                finisher, \n",
        "                ngram_1, \n",
        "                ngram_2, \n",
        "                hashingTF_1, \n",
        "                hashingTF_2, \n",
        "                idf_hash_1, \n",
        "                idf_hash_2, \n",
        "                document_assembler_2,\n",
        "                regexTokenizer_2,\n",
        "                finisher_2,\n",
        "                ngram_3, \n",
        "                ngram_4, \n",
        "                hashingTF_3, \n",
        "                hashingTF_4, \n",
        "                idf_hash_3, \n",
        "                idf_hash_4,\n",
        "                assembler, \n",
        "                indexer,\n",
        "                rf\n",
        "                  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccf6JqBCT7ZR"
      },
      "source": [
        "## 2.3 keras pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqC-Chg3UBJf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOGAgfMBUIni"
      },
      "source": [
        "# 3. classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Y-s5yMpdlJ"
      },
      "source": [
        "## 3.1 spark ml classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQYdwDfpcbxl"
      },
      "source": [
        "pipelineFit_nb = pipeline.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7yJ2ZXmm2US"
      },
      "source": [
        "pipelineFit_nb = nb.fit(pipelined)\n",
        "pipelineFit_lr = lr.fit(pipelined)\n",
        "pipelineFit_rf = rf.fit(pipelined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV3lX8zzg_1q"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "df_bayes = pipelineFit_nb \\\n",
        "    .transform(df_test) \\\n",
        "    .select(\"Category\", \"label\", \"prediction\", \"sentense\")\n",
        "df_bayes_pandas = df_bayes.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IMhBJ8nkC-_",
        "outputId": "f92cdef4-f721-48cc-d530-37f642a59353"
      },
      "source": [
        "labels_df = df_bayes\\\n",
        "    .select(\"label\", \"Category\")\\\n",
        "    .distinct()\\\n",
        "    .orderBy(\"label\")\n",
        "labels_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------+\n",
            "|label| Category|\n",
            "+-----+---------+\n",
            "|  0.0|  Science|\n",
            "|  1.0| Business|\n",
            "|  2.0|  Society|\n",
            "|  3.0|Computers|\n",
            "|  4.0|     Arts|\n",
            "+-----+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CoizvXdkRIE",
        "outputId": "66d32506-732b-42df-d795-ff48772118a8"
      },
      "source": [
        "labels_raw = labels_df.collect()\n",
        "labels = [row.Category for row in labels_raw]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Science', 'Business', 'Society', 'Computers', 'Arts']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_lUf2qXkdKx",
        "outputId": "4f100692-6752-4253-ec07-53b02f732391"
      },
      "source": [
        "print(classification_report(df_bayes_pandas.label, df_bayes_pandas.prediction, target_names=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Science       0.53      0.55      0.54      4523\n",
            "    Business       0.50      0.51      0.51      4518\n",
            "     Society       0.42      0.38      0.40      4419\n",
            "   Computers       0.46      0.47      0.47      4501\n",
            "        Arts       0.48      0.49      0.48      4638\n",
            "\n",
            "    accuracy                           0.48     22599\n",
            "   macro avg       0.48      0.48      0.48     22599\n",
            "weighted avg       0.48      0.48      0.48     22599\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH_CI7iVIRBo"
      },
      "source": [
        "## 3.2 sparknlp ml naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw9sSfypIAZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b1a713-0a19-4bb8-f2e5-65c1a6b76270"
      },
      "source": [
        "%%time\n",
        "pipelineFit_nb = pipeline_nb.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.24 s, sys: 141 ms, total: 1.39 s\n",
            "Wall time: 3min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpgXnjtxI4Kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4303d971-a03b-4ea1-9917-48ce39f3d2d4"
      },
      "source": [
        "df_bayes = pipelineFit_nb \\\n",
        "    .transform(df_test) \n",
        "df_bayes.show(5)\n",
        "#df_bayes.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Category|               title|                text|            document|            sentence|               token|         cleanTokens|               lemma|      token_features|             ngram_1|             ngram_2|       rawFeatures_1|       rawFeatures_2|          features_1|          features_2|          document_2|             token_2|    token_features_2|             ngram_3|             ngram_4|       rawFeatures_3|       rawFeatures_4|          features_3|          features_4|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Business|    1 horse property|specializing in e...|[[document, 0, 85...|[[document, 0, 85...|[[token, 0, 11, s...|[[token, 0, 11, s...|[[token, 0, 11, s...|[specialize, eque...|[specialize, eque...|[specialize eques...|(150,[33,42,60,65...|(150,[8,12,35,50,...|(150,[33,42,60,65...|(150,[8,12,35,50,...|[[document, 0, 15...|[[token, 0, 0, 1,...|[1, horse, property]|[1, horse, property]|[1 horse, horse p...|(150,[33,60,81],[...|(150,[50,110],[1....|(150,[33,60,81],[...|(150,[50,110],[3....|(600,[33,42,60,65...|  2.0|[-343.65201097996...|[3.73516373508798...|       1.0|\n",
            "|Business|1040 tax &amp; fi...|bakersfield firm ...|[[document, 0, 15...|[[document, 0, 98...|[[token, 0, 10, b...|[[token, 0, 10, b...|[[token, 0, 10, b...|[bakersfield, fir...|[bakersfield, fir...|[bakersfield firm...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|[[document, 0, 23...|[[token, 0, 3, 10...|[1040, tax, &amp,...|[1040, tax, &amp,...|[1040 tax, tax &a...|(150,[19,30,51,10...|(150,[38,59,131,1...|(150,[19,30,51,10...|(150,[38,59,131,1...|(600,[7,8,24,28,3...|  2.0|[-771.00162149311...|[1.21649077641390...|       2.0|\n",
            "|Business|       3m: aerospace|adhesives, abrasi...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[adhesive, ,, abr...|[adhesive, ,, abr...|[adhesive ,, , ab...|(150,[7,28,67,71,...|(150,[17,26,28,68...|(150,[7,28,67,71,...|(150,[17,26,28,68...|[[document, 0, 12...|[[token, 0, 1, 3m...|  [3m, :, aerospace]|  [3m, :, aerospace]| [3m :, : aerospace]|(150,[43,62,113],...|(150,[2,124],[1.0...|(150,[43,62,113],...|(150,[2,124],[4.1...|(600,[7,28,67,71,...|  2.0|[-365.78378330633...|[0.02858126171985...|       1.0|\n",
            "|Business|a &amp; t managem...|provides taxation...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 7, pr...|[[token, 9, 16, t...|[[token, 9, 16, t...|[taxation, ,, acc...|[taxation, ,, acc...|[taxation ,, , ac...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|[[document, 0, 31...|[[token, 0, 0, a,...|[a, &amp, ;, t, m...|[a, &amp, ;, t, m...|[a &amp, &amp ;, ...|(150,[21,30,31,51...|(150,[59,61,81,12...|(150,[21,30,31,51...|(150,[59,61,81,12...|(600,[0,27,28,67,...|  2.0|[-431.88785659573...|[3.91958843324154...|       2.0|\n",
            "|Business|aaa - eastern reg...|located east of t...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[locate, east, hu...|[locate, east, hu...|[locate east, eas...|(150,[28,89,121,1...|(150,[15,41,72,84...|(150,[28,89,121,1...|(150,[15,41,72,84...|[[document, 0, 24...|[[token, 0, 2, aa...|[aaa, -, eastern,...|[aaa, -, eastern,...|[aaa -, - eastern...|(150,[44,52,67,69...|(150,[27,76,94,12...|(150,[44,52,67,69...|(150,[27,76,94,12...|(600,[28,89,121,1...|  2.0|[-406.08268873210...|[6.61550328890196...|       3.0|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN_Q4UcBUlim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3319d926-97c0-4c8f-9afb-f515c08346ac"
      },
      "source": [
        "df_bayes.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Category: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- lemma: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_1: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_1: vector (nullable = true)\n",
            " |-- rawFeatures_2: vector (nullable = true)\n",
            " |-- features_1: vector (nullable = true)\n",
            " |-- features_2: vector (nullable = true)\n",
            " |-- document_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_3: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_4: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_3: vector (nullable = true)\n",
            " |-- rawFeatures_4: vector (nullable = true)\n",
            " |-- features_3: vector (nullable = true)\n",
            " |-- features_4: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgd6ybE6Ub5C"
      },
      "source": [
        "df_bayes_1 = df_bayes.select(\"Category\", \"label\", \"prediction\", \"text\")\n",
        "df_bayes_pandas = df_bayes_1.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EHjd_NYI8Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ec2637-080a-4e94-9f80-c4cb9e21b80d"
      },
      "source": [
        "labels_df = df_bayes\\\n",
        "    .select(\"label\", \"Category\")\\\n",
        "    .distinct()\\\n",
        "    .orderBy(\"label\")\n",
        "labels_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------+\n",
            "|label| Category|\n",
            "+-----+---------+\n",
            "|  0.0|  Science|\n",
            "|  1.0|  Society|\n",
            "|  2.0| Business|\n",
            "|  3.0|     Arts|\n",
            "|  4.0|Computers|\n",
            "+-----+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj5ZE34iI_IO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961c6acc-ce7d-46cb-ff6e-f8a50eb4bca7"
      },
      "source": [
        "labels_raw = labels_df.collect()\n",
        "labels = [row.Category for row in labels_raw]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Science', 'Society', 'Business', 'Arts', 'Computers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ni4xMhHJAJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b232bf-ed71-46c9-f814-3ec9ed21e810"
      },
      "source": [
        "print(classification_report(df_bayes_pandas.label, df_bayes_pandas.prediction, target_names=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Science       0.49      0.48      0.49      1525\n",
            "     Society       0.53      0.51      0.52      1462\n",
            "    Business       0.65      0.62      0.63      1533\n",
            "        Arts       0.63      0.64      0.63      1531\n",
            "   Computers       0.55      0.59      0.57      1517\n",
            "\n",
            "    accuracy                           0.57      7568\n",
            "   macro avg       0.57      0.57      0.57      7568\n",
            "weighted avg       0.57      0.57      0.57      7568\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYFbSP2VOaOU"
      },
      "source": [
        "## 3.3 sparknlp ml logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ-Rj95yOaOV",
        "outputId": "22948405-bd14-4886-c9a0-c68168c15fdb"
      },
      "source": [
        "%%time\n",
        "pipelineFit_lr = pipeline_lr.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.11 s, sys: 143 ms, total: 1.26 s\n",
            "Wall time: 2min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nyTXwx4OaOW",
        "outputId": "5f8f7c82-2cbc-4ed4-a666-a837832b6d2a"
      },
      "source": [
        "df_lr = pipelineFit_lr \\\n",
        "    .transform(df_test) \n",
        "df_lr.show(5)\n",
        "#df_lr.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Category|               title|                text|            document|            sentence|               token|         cleanTokens|               lemma|      token_features|             ngram_1|             ngram_2|       rawFeatures_1|       rawFeatures_2|          features_1|          features_2|          document_2|             token_2|    token_features_2|             ngram_3|             ngram_4|       rawFeatures_3|       rawFeatures_4|          features_3|          features_4|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Business|    1 horse property|specializing in e...|[[document, 0, 85...|[[document, 0, 85...|[[token, 0, 11, s...|[[token, 0, 11, s...|[[token, 0, 11, s...|[specialize, eque...|[specialize, eque...|[specialize eques...|(150,[33,42,60,65...|(150,[8,12,35,50,...|(150,[33,42,60,65...|(150,[8,12,35,50,...|[[document, 0, 15...|[[token, 0, 0, 1,...|[1, horse, property]|[1, horse, property]|[1 horse, horse p...|(150,[33,60,81],[...|(150,[50,110],[1....|(150,[33,60,81],[...|(150,[50,110],[3....|(600,[33,42,60,65...|  2.0|[0.00364840577442...|[0.20072835718177...|       0.0|\n",
            "|Business|1040 tax &amp; fi...|bakersfield firm ...|[[document, 0, 15...|[[document, 0, 98...|[[token, 0, 10, b...|[[token, 0, 10, b...|[[token, 0, 10, b...|[bakersfield, fir...|[bakersfield, fir...|[bakersfield firm...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|[[document, 0, 23...|[[token, 0, 3, 10...|[1040, tax, &amp,...|[1040, tax, &amp,...|[1040 tax, tax &a...|(150,[19,30,51,10...|(150,[38,59,131,1...|(150,[19,30,51,10...|(150,[38,59,131,1...|(600,[7,8,24,28,3...|  2.0|[0.00364840577442...|[0.20072835718177...|       0.0|\n",
            "|Business|       3m: aerospace|adhesives, abrasi...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[adhesive, ,, abr...|[adhesive, ,, abr...|[adhesive ,, , ab...|(150,[7,28,67,71,...|(150,[17,26,28,68...|(150,[7,28,67,71,...|(150,[17,26,28,68...|[[document, 0, 12...|[[token, 0, 1, 3m...|  [3m, :, aerospace]|  [3m, :, aerospace]| [3m :, : aerospace]|(150,[43,62,113],...|(150,[2,124],[1.0...|(150,[43,62,113],...|(150,[2,124],[4.1...|(600,[7,28,67,71,...|  2.0|[0.00364840577442...|[0.20072835718177...|       0.0|\n",
            "|Business|a &amp; t managem...|provides taxation...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 7, pr...|[[token, 9, 16, t...|[[token, 9, 16, t...|[taxation, ,, acc...|[taxation, ,, acc...|[taxation ,, , ac...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|[[document, 0, 31...|[[token, 0, 0, a,...|[a, &amp, ;, t, m...|[a, &amp, ;, t, m...|[a &amp, &amp ;, ...|(150,[21,30,31,51...|(150,[59,61,81,12...|(150,[21,30,31,51...|(150,[59,61,81,12...|(600,[0,27,28,67,...|  2.0|[0.00364840577442...|[0.20072835718177...|       0.0|\n",
            "|Business|aaa - eastern reg...|located east of t...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[locate, east, hu...|[locate, east, hu...|[locate east, eas...|(150,[28,89,121,1...|(150,[15,41,72,84...|(150,[28,89,121,1...|(150,[15,41,72,84...|[[document, 0, 24...|[[token, 0, 2, aa...|[aaa, -, eastern,...|[aaa, -, eastern,...|[aaa -, - eastern...|(150,[44,52,67,69...|(150,[27,76,94,12...|(150,[44,52,67,69...|(150,[27,76,94,12...|(600,[28,89,121,1...|  2.0|[0.00364840577442...|[0.20072835718177...|       0.0|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGjZU1vpOaOY",
        "outputId": "ab0f7aa0-7e75-47f2-c452-fb95a788836b"
      },
      "source": [
        "df_lr.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Category: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- lemma: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_1: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_1: vector (nullable = true)\n",
            " |-- rawFeatures_2: vector (nullable = true)\n",
            " |-- features_1: vector (nullable = true)\n",
            " |-- features_2: vector (nullable = true)\n",
            " |-- document_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_3: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_4: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_3: vector (nullable = true)\n",
            " |-- rawFeatures_4: vector (nullable = true)\n",
            " |-- features_3: vector (nullable = true)\n",
            " |-- features_4: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeR2Ih6AOaOa"
      },
      "source": [
        "df_lr_1 = df_lr.select(\"Category\", \"label\", \"prediction\", \"text\")\n",
        "df_lr_pandas = df_lr_1.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCIekZjVOaOb",
        "outputId": "4b0520b8-96f1-4ee8-e744-9754df140b4f"
      },
      "source": [
        "labels_df = df_lr\\\n",
        "    .select(\"label\", \"Category\")\\\n",
        "    .distinct()\\\n",
        "    .orderBy(\"label\")\n",
        "labels_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------+\n",
            "|label| Category|\n",
            "+-----+---------+\n",
            "|  0.0|  Science|\n",
            "|  1.0|  Society|\n",
            "|  2.0| Business|\n",
            "|  3.0|     Arts|\n",
            "|  4.0|Computers|\n",
            "+-----+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu6HbhD3OaOc",
        "outputId": "79b70c6f-1dc8-4772-a9d0-a97560434d45"
      },
      "source": [
        "labels_raw = labels_df.collect()\n",
        "labels = [row.Category for row in labels_raw]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Science', 'Society', 'Business', 'Arts', 'Computers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOlEVR2rOaOe",
        "outputId": "324be139-0f57-48ce-b5dc-9131772d19b0"
      },
      "source": [
        "print(classification_report(df_lr_pandas.label, df_lr_pandas.prediction, target_names=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Science       0.20      1.00      0.34      1525\n",
            "     Society       0.00      0.00      0.00      1462\n",
            "    Business       0.00      0.00      0.00      1533\n",
            "        Arts       0.00      0.00      0.00      1531\n",
            "   Computers       0.00      0.00      0.00      1517\n",
            "\n",
            "    accuracy                           0.20      7568\n",
            "   macro avg       0.04      0.20      0.07      7568\n",
            "weighted avg       0.04      0.20      0.07      7568\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_JvJWORPFl1"
      },
      "source": [
        "## 3.4 sparknlp ml random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g89UBBtRPFl3",
        "outputId": "9e87ffac-440c-48bc-e351-e8b5d7681e5c"
      },
      "source": [
        "%%time\n",
        "pipelineFit_rf = pipeline_rf.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.7 s, sys: 214 ms, total: 1.91 s\n",
            "Wall time: 5min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90ROm2dwPFl4",
        "outputId": "676b1397-a756-42fd-ebd6-404d9a033382"
      },
      "source": [
        "df_rf = pipelineFit_rf \\\n",
        "    .transform(df_test) \n",
        "df_rf.show(5)\n",
        "#df_rf.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Category|               title|                text|            document|            sentence|               token|         cleanTokens|               lemma|      token_features|             ngram_1|             ngram_2|       rawFeatures_1|       rawFeatures_2|          features_1|          features_2|          document_2|             token_2|    token_features_2|             ngram_3|             ngram_4|       rawFeatures_3|       rawFeatures_4|          features_3|          features_4|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|Business|    1 horse property|specializing in e...|[[document, 0, 85...|[[document, 0, 85...|[[token, 0, 11, s...|[[token, 0, 11, s...|[[token, 0, 11, s...|[specialize, eque...|[specialize, eque...|[specialize eques...|(150,[33,42,60,65...|(150,[8,12,35,50,...|(150,[33,42,60,65...|(150,[8,12,35,50,...|[[document, 0, 15...|[[token, 0, 0, 1,...|[1, horse, property]|[1, horse, property]|[1 horse, horse p...|(150,[33,60,81],[...|(150,[50,110],[1....|(150,[33,60,81],[...|(150,[50,110],[3....|(600,[33,42,60,65...|  2.0|[19.2128194609397...|[0.19212819460939...|       3.0|\n",
            "|Business|1040 tax &amp; fi...|bakersfield firm ...|[[document, 0, 15...|[[document, 0, 98...|[[token, 0, 10, b...|[[token, 0, 10, b...|[[token, 0, 10, b...|[bakersfield, fir...|[bakersfield, fir...|[bakersfield firm...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|(150,[7,8,24,28,3...|(150,[0,3,10,47,4...|[[document, 0, 23...|[[token, 0, 3, 10...|[1040, tax, &amp,...|[1040, tax, &amp,...|[1040 tax, tax &a...|(150,[19,30,51,10...|(150,[38,59,131,1...|(150,[19,30,51,10...|(150,[38,59,131,1...|(600,[7,8,24,28,3...|  2.0|[13.7244384373292...|[0.13724438437329...|       2.0|\n",
            "|Business|       3m: aerospace|adhesives, abrasi...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[[token, 0, 8, ad...|[adhesive, ,, abr...|[adhesive, ,, abr...|[adhesive ,, , ab...|(150,[7,28,67,71,...|(150,[17,26,28,68...|(150,[7,28,67,71,...|(150,[17,26,28,68...|[[document, 0, 12...|[[token, 0, 1, 3m...|  [3m, :, aerospace]|  [3m, :, aerospace]| [3m :, : aerospace]|(150,[43,62,113],...|(150,[2,124],[1.0...|(150,[43,62,113],...|(150,[2,124],[4.1...|(600,[7,28,67,71,...|  2.0|[20.2788242276478...|[0.20278824227647...|       1.0|\n",
            "|Business|a &amp; t managem...|provides taxation...|[[document, 0, 55...|[[document, 0, 55...|[[token, 0, 7, pr...|[[token, 9, 16, t...|[[token, 9, 16, t...|[taxation, ,, acc...|[taxation, ,, acc...|[taxation ,, , ac...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|(150,[0,27,28,67,...|(150,[6,11,19,32,...|[[document, 0, 31...|[[token, 0, 0, a,...|[a, &amp, ;, t, m...|[a, &amp, ;, t, m...|[a &amp, &amp ;, ...|(150,[21,30,31,51...|(150,[59,61,81,12...|(150,[21,30,31,51...|(150,[59,61,81,12...|(600,[0,27,28,67,...|  2.0|[16.3962122475774...|[0.16396212247577...|       2.0|\n",
            "|Business|aaa - eastern reg...|located east of t...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[[token, 0, 6, lo...|[locate, east, hu...|[locate, east, hu...|[locate east, eas...|(150,[28,89,121,1...|(150,[15,41,72,84...|(150,[28,89,121,1...|(150,[15,41,72,84...|[[document, 0, 24...|[[token, 0, 2, aa...|[aaa, -, eastern,...|[aaa, -, eastern,...|[aaa -, - eastern...|(150,[44,52,67,69...|(150,[27,76,94,12...|(150,[44,52,67,69...|(150,[27,76,94,12...|(600,[28,89,121,1...|  2.0|[19.4488169162965...|[0.19448816916296...|       3.0|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrBo9HVxPFl7",
        "outputId": "26412edf-e552-4231-87b8-63dcbf3e7fb7"
      },
      "source": [
        "df_rf.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Category: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- lemma: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_1: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_1: vector (nullable = true)\n",
            " |-- rawFeatures_2: vector (nullable = true)\n",
            " |-- features_1: vector (nullable = true)\n",
            " |-- features_2: vector (nullable = true)\n",
            " |-- document_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_2: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features_2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_3: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ngram_4: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rawFeatures_3: vector (nullable = true)\n",
            " |-- rawFeatures_4: vector (nullable = true)\n",
            " |-- features_3: vector (nullable = true)\n",
            " |-- features_4: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp62f-4jPFl8"
      },
      "source": [
        "df_rf_1 = df_rf.select(\"Category\", \"label\", \"prediction\", \"text\")\n",
        "df_rf_pandas = df_rf_1.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYaYiScbPFmA",
        "outputId": "9c9b4847-e7ce-47ff-f363-ca367aacd770"
      },
      "source": [
        "labels_df = df_rf\\\n",
        "    .select(\"label\", \"Category\")\\\n",
        "    .distinct()\\\n",
        "    .orderBy(\"label\")\n",
        "labels_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------+\n",
            "|label| Category|\n",
            "+-----+---------+\n",
            "|  0.0|  Science|\n",
            "|  1.0|  Society|\n",
            "|  2.0| Business|\n",
            "|  3.0|     Arts|\n",
            "|  4.0|Computers|\n",
            "+-----+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KMFDxcyPFmC",
        "outputId": "bfab4542-7001-41f3-f1af-d884ecfa08aa"
      },
      "source": [
        "labels_raw = labels_df.collect()\n",
        "labels = [row.Category for row in labels_raw]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Science', 'Society', 'Business', 'Arts', 'Computers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL7ojrV9PFmD",
        "outputId": "6503f78d-d3b5-43ea-d83c-75d083e11156"
      },
      "source": [
        "print(classification_report(df_rf_pandas.label, df_rf_pandas.prediction, target_names=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Science       0.47      0.31      0.37      1525\n",
            "     Society       0.41      0.47      0.43      1462\n",
            "    Business       0.53      0.58      0.55      1533\n",
            "        Arts       0.50      0.67      0.57      1531\n",
            "   Computers       0.53      0.41      0.46      1517\n",
            "\n",
            "    accuracy                           0.49      7568\n",
            "   macro avg       0.49      0.49      0.48      7568\n",
            "weighted avg       0.49      0.49      0.48      7568\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di26yn9jSCux"
      },
      "source": [
        "## 3.5 keras deep learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-W6r5QFMxdO"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=784))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed-LvZC6ECWc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,input_shape=(100,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-OazSadI8sc"
      },
      "source": [
        "spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')\n",
        "spark_model.fit(rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJk-IFD4JQI1"
      },
      "source": [
        "x_test, y_test = ... # load test data\n",
        "\n",
        "predictions = spark_model.predict(x_test) # perform inference\n",
        "evaluation = spark_model.evaluate(x_test, y_test) # perform evaluation/scoring"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP2SaB35Jk7y"
      },
      "source": [
        "estimator = ElephasEstimator(model, epochs=epochs, batch_size=batch_size, frequency='batch', mode='asynchronous',\n",
        "                             categorical=True, nb_classes=nb_classes)\n",
        "fitted_model = estimator.fit(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-vT1TnlJoKB"
      },
      "source": [
        "prediction = fitted_model.transform(test_df)\n",
        "pnl = prediction.select(\"label\", \"prediction\")\n",
        "pnl.show(100)\n",
        "\n",
        "prediction_and_label= pnl.rdd.map(lambda row: (row.label, row.prediction))\n",
        "metrics = MulticlassMetrics(prediction_and_label)\n",
        "print(metrics.precision())\n",
        "print(metrics.recall())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yikwplfSFq0j"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=3010, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(160, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(120, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(80, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(20, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hx5HyxmEIDQ"
      },
      "source": [
        "model.fit(tfidf_mat,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4F-cqPNFobw"
      },
      "source": [
        "print(\"Compile model ...\")\n",
        "estimator = KerasClassifier(build_fn=build_model, epochs=15, batch_size=128)\n",
        "estimator.fit(X, dummy_y_train)\n",
        "\n",
        "# Predictions \n",
        "print (\"Predict on test data ... \")\n",
        "y_test = estimator.predict(X_test)\n",
        "y_pred = lb.inverse_transform(y_test)\n",
        "\n",
        "# Submission\n",
        "print (\"Generate Submission File ... \")\n",
        "test_id = [doc['id'] for doc in test]\n",
        "sub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\n",
        "sub.to_csv('nn_output.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgSOlSk7KFc2"
      },
      "source": [
        "from hyperopt import STATUS_OK\n",
        "from hyperas.distributions import choice, uniform\n",
        "\n",
        "def data():\n",
        "    from tensorflow.keras.datasets import mnist\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    x_test = x_test.reshape(10000, 784)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    nb_classes = 10\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def model(x_train, y_train, x_test, y_test):\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    rms = RMSprop()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              nb_epoch=1,\n",
        "              show_accuracy=True,\n",
        "              verbose=2,\n",
        "              validation_data=(x_test, y_test))\n",
        "    score, acc = model.evaluate(x_test, y_test, show_accuracy=True, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model.to_yaml()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU6tReDeKGc7"
      },
      "source": [
        "from elephas.hyperparam import HyperParamModel\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Create Spark context\n",
        "conf = SparkConf().setAppName('Elephas_Hyperparameter_Optimization').setMaster('local[8]')\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# Define hyper-parameter model and run optimization\n",
        "hyperparam_model = HyperParamModel(sc)\n",
        "hyperparam_model.minimize(model=model, data=data, max_evals=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJ9d_WQKOV4"
      },
      "source": [
        "result = hyperparam_model.best_ensemble(nb_ensemble_models=10, model=model, data=data, max_evals=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}